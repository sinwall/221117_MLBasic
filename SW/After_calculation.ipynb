{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "output_path = './output/'\n",
    "try:\n",
    "    _=os.listdir(output_path)\n",
    "except:\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation modules\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay,RocCurveDisplay\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from data_loader_default import load_data_default\n",
    "def my_score(y_train,y_pred):\n",
    "    accuracy = accuracy_score(y_train,y_pred)\n",
    "    print(f'accuracy : {accuracy}')\n",
    "    pre_score = precision_score(y_train,y_pred)\n",
    "    print(f'precision : {pre_score}')\n",
    "    rec_score = recall_score(y_train,y_pred)\n",
    "    print(f'recall : {rec_score}')\n",
    "    f_score = f1_score(y_train,y_pred)\n",
    "    print(f'f1_score: {f_score}')\n",
    "\n",
    "    return [round(accuracy,4), round(pre_score,4), round(rec_score ,4), round(f_score,4)]\n",
    "\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds,ax=None):\n",
    "    if ax is None:\n",
    "        plt.plot(thresholds, precisions[:-1], 'b--', label=\"Precision\")\n",
    "        plt.plot(thresholds, recalls[:-1], 'g-',label=\"recall\")\n",
    "        plt.xlabel(\"thresholds\")\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.ylim([0,1])\n",
    "    else:\n",
    "        ax.plot(thresholds, precisions[:-1], 'b--', label=\"Precision\")\n",
    "        ax.plot(thresholds, recalls[:-1], 'g-',label=\"recall\")\n",
    "        ax.set_xlabel(\"thresholds\")\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "X_train,y_train,X_val,y_val = 0,0,0,0\n",
    "def plot_my_graphs(pred_train,pred_val,score_val,name=None):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=2\n",
    "\n",
    "def my_func(x,y):\n",
    "    print(z)\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_py_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abb538871b4e03b427e9482af4cbea7329408220ff7b8d0c3bc51f0a54e037b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
